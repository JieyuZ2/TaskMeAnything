{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing Top K Query and Query Results Approximation in Task-Me-Anything\n",
    "\n",
    "In this notebook, we will show how to perform a “Top K Query” in Task-Me-Anything. We’ll focus on identify the top 10 worst-performing task plans of `llavav1.5-7b` over 3200+ task plans on “2D sticker how many” task type. After that, we willl using `Fit` and `Active` query results approximation algorithms to approximate the performance of tasks plan within only 500 budgets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate tasks\n",
    "\n",
    "These are the process of task plans generation, illustrations on these part will be in the `generate` part of demo.\n",
    "\n",
    "In this step, we generate 3,249 “how many” task plans in 2D scenarios. Each task plan contains all the configuration and content needed to generate an image-question pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "enumerating [how many attribute 1] task: 100%|██████████| 3/3 [00:00<00:00, 8659.95it/s]\n",
      "enumerating [how many attribute 2] task: 100%|██████████| 465/465 [00:01<00:00, 259.03it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task type</th>\n",
       "      <th>grid number</th>\n",
       "      <th>target category</th>\n",
       "      <th>count</th>\n",
       "      <th>attribute type</th>\n",
       "      <th>attribute value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how many</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>color</td>\n",
       "      <td>blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>how many</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>7</td>\n",
       "      <td>color</td>\n",
       "      <td>blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>how many</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>4</td>\n",
       "      <td>color</td>\n",
       "      <td>gold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>how many</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>color</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>how many</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>color</td>\n",
       "      <td>yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32440</th>\n",
       "      <td>how many</td>\n",
       "      <td>2</td>\n",
       "      <td>Q99895</td>\n",
       "      <td>4</td>\n",
       "      <td>color</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32450</th>\n",
       "      <td>how many</td>\n",
       "      <td>3</td>\n",
       "      <td>Q99895</td>\n",
       "      <td>2</td>\n",
       "      <td>color</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32460</th>\n",
       "      <td>how many</td>\n",
       "      <td>3</td>\n",
       "      <td>Q99895</td>\n",
       "      <td>4</td>\n",
       "      <td>color</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32470</th>\n",
       "      <td>how many</td>\n",
       "      <td>3</td>\n",
       "      <td>Q99895</td>\n",
       "      <td>6</td>\n",
       "      <td>color</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32480</th>\n",
       "      <td>how many</td>\n",
       "      <td>3</td>\n",
       "      <td>Q99895</td>\n",
       "      <td>8</td>\n",
       "      <td>color</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3249 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      task type  grid number target category  count attribute type  \\\n",
       "0      how many            2            <NA>      1          color   \n",
       "10     how many            3            <NA>      7          color   \n",
       "20     how many            3            <NA>      4          color   \n",
       "30     how many            3            <NA>      1          color   \n",
       "40     how many            2            <NA>      2          color   \n",
       "...         ...          ...             ...    ...            ...   \n",
       "32440  how many            2          Q99895      4          color   \n",
       "32450  how many            3          Q99895      2          color   \n",
       "32460  how many            3          Q99895      4          color   \n",
       "32470  how many            3          Q99895      6          color   \n",
       "32480  how many            3          Q99895      8          color   \n",
       "\n",
       "      attribute value  \n",
       "0                blue  \n",
       "10               blue  \n",
       "20               gold  \n",
       "30              black  \n",
       "40             yellow  \n",
       "...               ...  \n",
       "32440           white  \n",
       "32450           white  \n",
       "32460           white  \n",
       "32470           white  \n",
       "32480           white  \n",
       "\n",
       "[3249 rows x 6 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "# set the working directory to the root of the project\n",
    "sys.path.append(\"../..\")\n",
    "from tma.imageqa.sticker_2d import *\n",
    "from tma.imageqa.metadata import Objaverse2DMetaData\n",
    "from tma.task_store import TaskStore\n",
    "\n",
    "# the code to download the source data, if you already downloaded the data, you can skip this step\n",
    "# from huggingface_hub import snapshot_download\n",
    "# path = \"../TaskMeAnything-v1-source\"\n",
    "# snapshot_download(repo_id=\"jieyuz2/TaskMeAnything-v1-source\", repo_type=\"dataset\", local_dir=path)\n",
    "\n",
    "\n",
    "\n",
    "path = '/your_path/TaskMeAnything-v1-source'\n",
    "metadata = Objaverse2DMetaData('../../annotations', image_folder=f'{path}/object_images')\n",
    "generator = HowManyGridTaskGenerator(metadata)\n",
    "\n",
    "\n",
    "# enumerate all \"how many\" task plans\n",
    "task_store = TaskStore(generator.schema)\n",
    "generator.enumerate_task_plans(task_store)\n",
    "df = task_store.return_df()\n",
    "\n",
    "\n",
    "# sample a subset of the all \"how many\" task plans\n",
    "interval = len(df) // 3000\n",
    "df = df.iloc[::interval, :]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding the tasks and create VQATaskEvaluator\n",
    "\n",
    "\n",
    "Task evaluator takes the model and the tasks as input, and evaluate and query the model's performance on the tasks generated by task plans. \n",
    "\n",
    "\n",
    "\n",
    "<!-- Because we want to fit a performance regressor, we need to embed the tasks. We will use the Cohere API to embed the tasks. First you need to set the `api_key` parameter to your Cohere API key. You can also using other embedding API or models to embed the tasks. (e.g Openai embedding API, BERT, etc.)\n",
    "\n",
    "Then you should create a `VQATaskEvaluator` object. `VQATaskEvaluator` is a class designed to evaluate a model's performance on task. It can handle the details in evaluate the model such as create the embedding of the tasks, fit the performance regressor, etc.\n",
    "\n",
    "Notice that `VQATaskEvaluator` can cache the embeddings to avoid redundant requests to the OpenAI API. You can change the path of the cache file by setting the `cache_path` parameter. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tma.task_evaluator import VQATaskEvaluator\n",
    "\n",
    "task_evaluator = VQATaskEvaluator(\n",
    "    task_plan_df=df, # data frames task plans to evaluate\n",
    "    task_generator=generator, # task generator, used to generate test instances for each task plan\n",
    "    embedding_name='st',  # using sentence transformer (st) to embedding questions\n",
    "    embedding_batch_size=10000,  # batch size for embedding\n",
    "    n_instance_per_task=5,  # number of test instances generated per task plan\n",
    "    n_trials_per_instance=3,  # number of trials per test instance\n",
    "    cache_path_root=\".cache\",  # enter you path for cache\n",
    "    seed=42  # random seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model on all the task plans\n",
    "\n",
    "In this steps, we will start to get the ground truth of the query. We will not use query approximation algorithms in this step. Instead, we will evaluate the model on all the tasks and get the top 10 worst-performing tasks as the ground truth. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can call tma.models.qa_model.list_vqa_models() to find all the available VQA models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['instructblip-flant5xl',\n",
       " 'instructblip-flant5xxl',\n",
       " 'instructblip-vicuna7b',\n",
       " 'instructblip-vicuna13b',\n",
       " 'blip2-flant5xxl',\n",
       " 'llavav1.5-7b',\n",
       " 'llavav1.5-13b',\n",
       " 'llavav1.6-34b',\n",
       " 'llava1.6-34b-api',\n",
       " 'qwenvl',\n",
       " 'qwenvl-chat',\n",
       " 'internvl-chat-v1.5',\n",
       " 'gpt4v',\n",
       " 'gpt4o',\n",
       " 'qwen-vl-plus',\n",
       " 'qwen-vl-max',\n",
       " 'gemini-vision-pro']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tma.models.qa_model import list_imageqa_models\n",
    "\n",
    "# list all available models\n",
    "list_imageqa_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use `llavav1.5-7b` for showcasing, you can use other models you like or using multi-models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IMPORTANT] model cache is enabled, cache path: .cache/\n",
      "Loading llavav1.5-7b...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1086916f6b974c91b03934c4b2d82a8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish loading llavav1.5-7b\n"
     ]
    }
   ],
   "source": [
    "from tma.models.qa_model import ImageQAModel\n",
    "from tma.models.qa_model import prompt\n",
    "import torch\n",
    "\n",
    "# single model\n",
    "model = ImageQAModel(model_name='llavav1.5-7b', precision=torch.bfloat16, prompt_name = \"succinct_prompt\", prompt_func=prompt.succinct_prompt, cache_path = \".cache/\")\n",
    "\n",
    "# # multiple models\n",
    "# # Notice: If you have multiple GPUs, you can set the torch_device for each model to avoid running out of GPU memory.\n",
    "# model1 = ImageQAModel(model_name='llavav1.5-7b', torch_device=0, precision=torch.bfloat16, prompt_name = \"succinct_prompt\", prompt_func=prompt.succinct_prompt, cache_path = \".cache/\")\n",
    "# model2 = ImageQAModel(model_name='qwenvl-chat', torch_device=1, precision=torch.bfloat16, prompt_name = \"succinct_prompt\", prompt_func=prompt.succinct_prompt, cache_path = \".cache/\")\n",
    " \n",
    "# model = [model1, model2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate our model’s performance across different grouped categories, we follow a systematic approach:\n",
    "\n",
    "1.\tGetting Score on Each Task Plan: For each task plan, we generate multiple questions. We then calculate the model’s aggregate score across these questions. This aggregate score provides a comprehensive measure of the model’s performance for each task plan.\n",
    "2.\tGrouping: We group different task plans by their “target category,” which is the category of the object that serves as the answer for a task plan. All test cases with the same target category are grouped together.\n",
    "3.\tAverage Score Calculation: For each category, we calculate the average score using the scores of the task plans within that category.\n",
    "4.\tRanking: Finally, we rank the categories based on their average scores and identify the top k categories where the model has the lowest average scores, indicating its weakest performance areas.\n",
    "\n",
    "Example: Suppose there are 3 task plans where the answer to each plan is “banana.” For each task plan, we generate 3 task instances, resulting in 3 * 3 = 9 test instances. We evaluate the model on all 9 test instances and calculate the average score for each task plan. Since these 3 task plans all have “banana” as the answer, they are grouped together as a single category. The average score of the “banana” category is calculated using the aggregate scores of these 3 task plans. We then use this average score to rank the “banana” category among other categories.\n",
    "\n",
    "Here we represent task categories in the format of QID, The values start with \"Q\" is the QID of the category, which corresponds to a Wikidata entry (eg,  `Q11422` corresponds to https://www.wikidata.org/wiki/Q11422)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating tasks: 100%|██████████| 3249/3249 [02:21<00:00, 22.90it/s] \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "groupby = \"target category\"\n",
    "ground_truth = np.array(task_evaluator.evaluate(model=model))\n",
    "indices = list(df.groupby(groupby).indices.items())\n",
    "aggregate_perf = np.array([np.mean(ground_truth[i]) for k, i in indices])\n",
    "category_to_rank = {indices[i][0]:rank for rank, i in enumerate(np.argsort(aggregate_perf))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Q207220': 0,\n",
       " 'Q161439': 1,\n",
       " 'Q13202263': 2,\n",
       " 'Q7220961': 3,\n",
       " 'Q849813': 4,\n",
       " 'Q2596997': 5,\n",
       " 'Q245761': 6,\n",
       " 'Q104555': 7,\n",
       " 'Q172833': 8,\n",
       " 'Q875696': 9,\n",
       " 'Q2750929': 10,\n",
       " 'Q42527': 11,\n",
       " 'Q1317634': 12,\n",
       " 'Q682582': 13,\n",
       " 'Q11422': 14,\n",
       " 'Q178': 15,\n",
       " 'Q37828': 16,\n",
       " 'Q35197': 17,\n",
       " 'Q16917685': 18,\n",
       " 'Q2248059': 19,\n",
       " 'Q107444': 20,\n",
       " 'Q155972': 21,\n",
       " 'Q29024343': 22,\n",
       " 'Q3962': 23,\n",
       " 'Q207763': 24,\n",
       " 'Q189299': 25,\n",
       " 'Q23664': 26,\n",
       " 'Q768186': 27,\n",
       " 'Q2637814': 28,\n",
       " 'Q170484': 29,\n",
       " 'Q5936788': 30,\n",
       " 'Q191851': 31,\n",
       " 'Q50643': 32,\n",
       " 'Q11285759': 33,\n",
       " 'Q104526': 34,\n",
       " 'Q19827042': 35,\n",
       " 'Q127666': 36,\n",
       " 'Q13681': 37,\n",
       " 'Q171446': 38,\n",
       " 'Q19968163': 39,\n",
       " 'Q196538': 40,\n",
       " 'Q3506176': 41,\n",
       " 'Q188075': 42,\n",
       " 'Q179904': 43,\n",
       " 'Q1798603': 44,\n",
       " 'Q131696': 45,\n",
       " 'Q12132': 46,\n",
       " 'Q4006': 47,\n",
       " 'Q101674': 48,\n",
       " 'Q939611': 49,\n",
       " 'Q44106': 50,\n",
       " 'Q729': 51,\n",
       " 'Q5113': 52,\n",
       " 'Q501862': 53,\n",
       " 'Q11035': 54,\n",
       " 'Q1129239': 55,\n",
       " 'Q42177': 56,\n",
       " 'Q6950796': 57,\n",
       " 'Q11460': 58,\n",
       " 'Q154': 59,\n",
       " 'Q16836622': 60,\n",
       " 'Q171495': 61,\n",
       " 'Q81881': 62,\n",
       " 'Q134205': 63,\n",
       " 'Q5994': 64,\n",
       " 'Q1629107': 65,\n",
       " 'Q2524539': 66,\n",
       " 'Q26995321': 67,\n",
       " 'Q39546': 68,\n",
       " 'Q14745': 69,\n",
       " 'Q859281': 70,\n",
       " 'Q213477': 71,\n",
       " 'Q2383811': 72,\n",
       " 'Q467505': 73,\n",
       " 'Q3773693': 74,\n",
       " 'Q200539': 75,\n",
       " 'Q2920313': 76,\n",
       " 'Q34379': 77,\n",
       " 'Q536135': 78,\n",
       " 'Q74048276': 79,\n",
       " 'Q862454': 80,\n",
       " 'Q27149326': 81,\n",
       " 'Q46335': 82,\n",
       " 'Q211841': 83,\n",
       " 'Q869381': 84,\n",
       " 'Q864114': 85,\n",
       " 'Q860861': 86,\n",
       " 'Q125356': 87,\n",
       " 'Q116221438': 88,\n",
       " 'Q744112': 89,\n",
       " 'Q853185': 90,\n",
       " 'Q234870': 91,\n",
       " 'Q14660': 92,\n",
       " 'Q123691907': 93,\n",
       " 'Q161928': 94,\n",
       " 'Q25403900': 95,\n",
       " 'Q185785': 96,\n",
       " 'Q131514': 97,\n",
       " 'Q36539': 98,\n",
       " 'Q116971226': 99,\n",
       " 'Q131647': 100,\n",
       " 'Q2160801': 101,\n",
       " 'Q41607': 102,\n",
       " 'Q201664': 103,\n",
       " 'Q1310214': 104,\n",
       " 'Q11789812': 105,\n",
       " 'Q191768': 106,\n",
       " 'Q849964': 107,\n",
       " 'Q212758': 108,\n",
       " 'Q5290': 109,\n",
       " 'Q182940': 110,\n",
       " 'Q4858753': 111,\n",
       " 'Q11019': 112,\n",
       " 'Q581105': 113,\n",
       " 'Q121916': 114,\n",
       " 'Q866153': 115,\n",
       " 'Q26988406': 116,\n",
       " 'Q958210': 117,\n",
       " 'Q99895': 118,\n",
       " 'Q165199': 119,\n",
       " 'Q728': 120,\n",
       " 'Q1384616': 121,\n",
       " 'Q115618359': 122,\n",
       " 'Q26972858': 123,\n",
       " 'Q1323314': 124,\n",
       " 'Q11472': 125,\n",
       " 'Q214488': 126,\n",
       " 'Q8076': 127,\n",
       " 'Q8492': 128,\n",
       " 'Q60310748': 129,\n",
       " 'Q1207302': 130,\n",
       " 'Q178794': 131,\n",
       " 'Q1146001': 132,\n",
       " 'Q11442': 133,\n",
       " 'Q311666': 134,\n",
       " 'Q14674': 135,\n",
       " 'Q43533': 136,\n",
       " 'Q106106': 137,\n",
       " 'Q22710': 138,\n",
       " 'Q102626': 139,\n",
       " 'Q865054': 140,\n",
       " 'Q613972': 141,\n",
       " 'Q755313': 142,\n",
       " 'Q17517': 143,\n",
       " 'Q22676': 144,\n",
       " 'Q2447985': 145,\n",
       " 'Q1760958': 146,\n",
       " 'Q40050': 147,\n",
       " 'Q1211272': 148,\n",
       " 'Q127197': 149,\n",
       " 'Q153988': 150,\n",
       " 'Q23504115': 151,\n",
       " 'Q5581528': 152,\n",
       " 'Q471898': 153,\n",
       " 'Q152574': 154,\n",
       " 'Q659495': 155,\n",
       " 'Q212920': 156,\n",
       " 'Q951964': 157,\n",
       " 'Q376': 158,\n",
       " 'Q6498398': 159,\n",
       " 'Q1333024': 160,\n",
       " 'Q2095': 161,\n",
       " 'Q1751850': 162,\n",
       " 'Q223269': 163,\n",
       " 'Q20134': 164,\n",
       " 'Q8075': 165,\n",
       " 'Q605384': 166,\n",
       " 'Q214649': 167,\n",
       " 'Q645292': 168,\n",
       " 'Q73498530': 169,\n",
       " 'Q185583': 170,\n",
       " 'Q11435': 171,\n",
       " 'Q855373': 172,\n",
       " 'Q57216': 173,\n",
       " 'Q186819': 174,\n",
       " 'Q46847': 175,\n",
       " 'Q182780': 176,\n",
       " 'Q147538': 177,\n",
       " 'Q13266': 178,\n",
       " 'Q2574750': 179,\n",
       " 'Q815738': 180,\n",
       " 'Q154411': 181,\n",
       " 'Q215857': 182,\n",
       " 'Q42378': 183,\n",
       " 'Q4388799': 184,\n",
       " 'Q38645': 185,\n",
       " 'Q5082128': 186,\n",
       " 'Q131740': 187,\n",
       " 'Q193955': 188,\n",
       " 'Q28932195': 189,\n",
       " 'Q3966': 190,\n",
       " 'Q838948': 191,\n",
       " 'Q104666136': 192,\n",
       " 'Q17489160': 193,\n",
       " 'Q200814': 194,\n",
       " 'Q122052040': 195,\n",
       " 'Q245005': 196,\n",
       " 'Q65284752': 197,\n",
       " 'Q265868': 198,\n",
       " 'Q1622390': 199,\n",
       " 'Q11629': 200,\n",
       " 'Q115921244': 201,\n",
       " 'Q170486': 202,\n",
       " 'Q1427887': 203,\n",
       " 'Q2715770': 204,\n",
       " 'Q8355': 205,\n",
       " 'Q28803': 206,\n",
       " 'Q213096': 207,\n",
       " 'Q115435012': 208,\n",
       " 'Q20459': 209,\n",
       " 'Q117209093': 210,\n",
       " 'Q134566': 211,\n",
       " 'Q1501968': 212,\n",
       " 'Q165447': 213,\n",
       " 'Q14963': 214,\n",
       " 'Q39908': 215,\n",
       " 'Q483634': 216,\n",
       " 'Q47722': 217,\n",
       " 'Q116961643': 218,\n",
       " 'Q132397': 219,\n",
       " 'Q4498085': 220,\n",
       " 'Q2142903': 221,\n",
       " 'Q15328': 222,\n",
       " 'Q7802': 223,\n",
       " 'Q446': 224,\n",
       " 'Q42622779': 225,\n",
       " 'Q36794': 226,\n",
       " 'Q3033123': 227,\n",
       " 'Q208440': 228,\n",
       " 'Q23490': 229,\n",
       " 'Q938319': 230,\n",
       " 'Q170984': 231,\n",
       " 'Q192234': 232,\n",
       " 'Q32489': 233,\n",
       " 'Q47107': 234,\n",
       " 'Q34735': 235,\n",
       " 'Q190868': 236,\n",
       " 'Q193897': 237,\n",
       " 'Q14952': 238,\n",
       " 'Q617239': 239,\n",
       " 'Q210723': 240,\n",
       " 'Q43013': 241,\n",
       " 'Q96952903': 242,\n",
       " 'Q1756633': 243,\n",
       " 'Q49013': 244,\n",
       " 'Q1355359': 245,\n",
       " 'Q1780509': 246,\n",
       " 'Q122973887': 247,\n",
       " 'Q2366864': 248,\n",
       " 'Q2741056': 249,\n",
       " 'Q1666865': 250,\n",
       " 'Q1501161': 251,\n",
       " 'Q185217': 252,\n",
       " 'Q2623418': 253,\n",
       " 'Q510176': 254,\n",
       " 'Q2000617': 255,\n",
       " 'Q1151042': 256,\n",
       " 'Q386215': 257,\n",
       " 'Q11946202': 258,\n",
       " 'Q10990': 259,\n",
       " 'Q1357': 260,\n",
       " 'Q131704': 261,\n",
       " 'Q1507442': 262,\n",
       " 'Q1021686': 263,\n",
       " 'Q14748': 264,\n",
       " 'Q152': 265,\n",
       " 'Q42889': 266,\n",
       " 'Q18545': 267,\n",
       " 'Q13049940': 268,\n",
       " 'Q140565': 269,\n",
       " 'Q1929383': 270,\n",
       " 'Q173725': 271,\n",
       " 'Q217541': 272,\n",
       " 'Q148958': 273,\n",
       " 'Q60142': 274,\n",
       " 'Q233040': 275,\n",
       " 'Q13422881': 276,\n",
       " 'Q110079': 277,\n",
       " 'Q222405': 278,\n",
       " 'Q4213': 279,\n",
       " 'Q749316': 280,\n",
       " 'Q758891': 281,\n",
       " 'Q132041': 282,\n",
       " 'Q2425052': 283,\n",
       " 'Q204776': 284,\n",
       " 'Q119720106': 285,\n",
       " 'Q46384': 286,\n",
       " 'Q17119302': 287,\n",
       " 'Q272502': 288,\n",
       " 'Q35473': 289,\n",
       " 'Q1136834': 290,\n",
       " 'Q80151': 291,\n",
       " 'Q81944': 292,\n",
       " 'Q31087': 293,\n",
       " 'Q107126067': 294,\n",
       " 'Q131746': 295,\n",
       " 'Q13479587': 296,\n",
       " 'Q13233': 297,\n",
       " 'Q51338': 298,\n",
       " 'Q1361086': 299,\n",
       " 'Q89': 300,\n",
       " 'Q14524031': 301,\n",
       " 'Q57583712': 302,\n",
       " 'Q152095': 303,\n",
       " 'Q1349717': 304,\n",
       " 'Q161071': 305,\n",
       " 'Q232254': 306,\n",
       " 'Q40847': 307,\n",
       " 'Q14890': 308,\n",
       " 'Q173517': 309,\n",
       " 'Q159391': 310,\n",
       " 'Q250': 311,\n",
       " 'Q191022': 312,\n",
       " 'Q80228': 313,\n",
       " 'Q16629185': 314,\n",
       " 'Q571': 315,\n",
       " 'Q134560': 316,\n",
       " 'Q2453629': 317,\n",
       " 'Q11012': 318,\n",
       " 'Q1744391': 319,\n",
       " 'Q5689512': 320,\n",
       " 'Q170124': 321,\n",
       " 'Q5159627': 322,\n",
       " 'Q2024731': 323,\n",
       " 'Q656656': 324,\n",
       " 'Q149757': 325,\n",
       " 'Q477248': 326,\n",
       " 'Q1368': 327,\n",
       " 'Q16868432': 328,\n",
       " 'Q3314483': 329,\n",
       " 'Q216530': 330,\n",
       " 'Q13191': 331,\n",
       " 'Q55417699': 332,\n",
       " 'Q1320546': 333,\n",
       " 'Q63917312': 334,\n",
       " 'Q148493': 335,\n",
       " 'Q1460219': 336,\n",
       " 'Q7927908': 337,\n",
       " 'Q5318': 338,\n",
       " 'Q3057632': 339,\n",
       " 'Q2426768': 340,\n",
       " 'Q1578': 341,\n",
       " 'Q170285': 342,\n",
       " 'Q2207370': 343,\n",
       " 'Q131419': 344,\n",
       " 'Q465453': 345,\n",
       " 'Q987767': 346,\n",
       " 'Q1047832': 347,\n",
       " 'Q217446': 348,\n",
       " 'Q6607': 349,\n",
       " 'Q1138737': 350,\n",
       " 'Q213777': 351,\n",
       " 'Q15026': 352,\n",
       " 'Q6147804': 353,\n",
       " 'Q1572702': 354,\n",
       " 'Q131207': 355,\n",
       " 'Q41298': 356,\n",
       " 'Q8495': 357,\n",
       " 'Q1064858': 358,\n",
       " 'Q1548030': 359,\n",
       " 'Q21167379': 360,\n",
       " 'Q15148': 361,\n",
       " 'Q12252328': 362,\n",
       " 'Q7987': 363,\n",
       " 'Q37501': 364,\n",
       " 'Q821952': 365,\n",
       " 'Q37152': 366,\n",
       " 'Q11404': 367,\n",
       " 'Q1820120': 368,\n",
       " 'Q506': 369,\n",
       " 'Q5843': 370,\n",
       " 'Q412770': 371,\n",
       " 'Q5953359': 372,\n",
       " 'Q809910': 373,\n",
       " 'Q327954': 374,\n",
       " 'Q1347864': 375,\n",
       " 'Q6887300': 376,\n",
       " 'Q273318': 377,\n",
       " 'Q381165': 378,\n",
       " 'Q1390': 379,\n",
       " 'Q58964': 380,\n",
       " 'Q232191': 381,\n",
       " 'Q13317': 382,\n",
       " 'Q2397485': 383,\n",
       " 'Q13276': 384,\n",
       " 'Q33163': 385,\n",
       " 'Q116434': 386,\n",
       " 'Q173603': 387,\n",
       " 'Q81727': 388,\n",
       " 'Q6817227': 389,\n",
       " 'Q133792': 390,\n",
       " 'Q223575': 391,\n",
       " 'Q234668': 392,\n",
       " 'Q1127296': 393,\n",
       " 'Q12888135': 394,\n",
       " 'Q161524': 395,\n",
       " 'Q235783': 396,\n",
       " 'Q201097': 397,\n",
       " 'Q756': 398,\n",
       " 'Q5881191': 399,\n",
       " 'Q14560': 400,\n",
       " 'Q45922': 401,\n",
       " 'Q192783': 402,\n",
       " 'Q1762457': 403,\n",
       " 'Q127956': 404,\n",
       " 'Q43663': 405,\n",
       " 'Q93189': 406,\n",
       " 'Q865422': 407,\n",
       " 'Q56139': 408,\n",
       " 'Q72797': 409,\n",
       " 'Q68': 410,\n",
       " 'Q41207': 411,\n",
       " 'Q28692583': 412,\n",
       " 'Q36641511': 413,\n",
       " 'Q169031': 414,\n",
       " 'Q124441': 415,\n",
       " 'Q190672': 416,\n",
       " 'Q121225283': 417,\n",
       " 'Q107293': 418,\n",
       " 'Q614467': 419,\n",
       " 'Q40614': 420,\n",
       " 'Q221994': 421,\n",
       " 'Q941818': 422,\n",
       " 'Q181055': 423,\n",
       " 'Q13099586': 424,\n",
       " 'Q13360264': 425,\n",
       " 'Q1531435': 426,\n",
       " 'Q81895': 427,\n",
       " 'Q867246': 428,\n",
       " 'Q168639': 429,\n",
       " 'Q10289': 430,\n",
       " 'Q41274': 431,\n",
       " 'Q1514280': 432,\n",
       " 'Q2009740': 433,\n",
       " 'Q3246832': 434,\n",
       " 'Q18696213': 435,\n",
       " 'Q107196890': 436,\n",
       " 'Q666242': 437,\n",
       " 'Q191931': 438,\n",
       " 'Q20638126': 439,\n",
       " 'Q213062': 440,\n",
       " 'Q8026408': 441,\n",
       " 'Q11634': 442,\n",
       " 'Q165308': 443,\n",
       " 'Q503': 444,\n",
       " 'Q11004': 445,\n",
       " 'Q177': 446,\n",
       " 'Q570': 447,\n",
       " 'Q1093742': 448,\n",
       " 'Q235041': 449,\n",
       " 'Q4439': 450,\n",
       " 'Q947211': 451,\n",
       " 'Q185091': 452,\n",
       " 'Q1419626': 453,\n",
       " 'Q39397': 454,\n",
       " 'Q599797': 455,\n",
       " 'Q3736439': 456,\n",
       " 'Q961769': 457,\n",
       " 'Q954087': 458,\n",
       " 'Q16338': 459,\n",
       " 'Q927924': 460,\n",
       " 'Q3067542': 461,\n",
       " 'Q82': 462,\n",
       " 'Q34687': 463,\n",
       " 'Q25294': 464}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_to_rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply query approximation algorithms\n",
    "Query approximation algorithms means only evaluate model on a subset of tasks and use the result to approximate the performance on the whole task plans.\n",
    "\n",
    "We will use the `Fit` algorithm and `Active` algorithm to approximate the top k worst query, and compare the performance of these two methods with the ground truth. For each algorithm, we will give 500 budgets, which means the approximation algorithm can only evaluate 500 task plans.\n",
    "\n",
    "* In the `Fit` approach, we randomly select 500 task plans and fit the function approximator.\n",
    "* In the `Active` approach, we start with 200 task plans and then gradually add more task plans to the training set based on the function approximator's predictions.\n",
    "\n",
    "For `Active` algorithm here is the details:\n",
    "Initially, we use VQA questions from 100 training task categories as a warm-up phase, allowing the regressor to roughly fit the model. Then, in each step, we select the top k worst queries based on the performance regressor’s predictions. - We then evaluate VQA models on these top k task categories and get actual result and add these new task categories to train the performance regressor, iterativly untill we run out of our budget. Basically, we are using the performance regressor to determine which data points to use and the VQA model to obtain actual performance data. This iterative process continues until we have utilized our entire budget. This algorithm is inspired by Bayesian optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is used to print the results of the query approximation algorithms' results compare with the ground truth\n",
    "def print_results(topk):\n",
    "    hit_count = 0\n",
    "    total_rank = 0\n",
    "\n",
    "    for i, (k, v) in enumerate(topk):\n",
    "        actual_rank = category_to_rank[k]\n",
    "        print(f\"category: {k:<10} predicted rank {i:<2} actual rank: {actual_rank:<3}\")\n",
    "        total_rank += actual_rank\n",
    "        if actual_rank <= len(topk):\n",
    "            hit_count += 1\n",
    "\n",
    "    mean_rank = total_rank / len(topk)\n",
    "    hit_rate = hit_count / len(topk)\n",
    "\n",
    "    print(f\"Mean Rank: {mean_rank:.2f}\")\n",
    "    print(f\"Hit Rate: {hit_rate:.2f}\")\n",
    "    \n",
    "    \n",
    "# set up the budget    \n",
    "budget = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use \"Fit\" approximation algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating tasks: 100%|██████████| 500/500 [00:03<00:00, 149.56it/s]\n",
      "Embedding tasks: 100%|██████████| 3249/3249 [00:01<00:00, 1682.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category: Q161439    predicted rank 0  actual rank: 1  \n",
      "category: Q11442     predicted rank 1  actual rank: 133\n",
      "category: Q875696    predicted rank 2  actual rank: 9  \n",
      "category: Q1317634   predicted rank 3  actual rank: 12 \n",
      "category: Q101674    predicted rank 4  actual rank: 48 \n",
      "category: Q265868    predicted rank 5  actual rank: 198\n",
      "category: Q207763    predicted rank 6  actual rank: 24 \n",
      "category: Q125356    predicted rank 7  actual rank: 87 \n",
      "category: Q50643     predicted rank 8  actual rank: 32 \n",
      "category: Q19827042  predicted rank 9  actual rank: 35 \n",
      "Mean Rank: 57.90\n",
      "Hit Rate: 0.20\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "perm = np.random.permutation(len(df))\n",
    "x_indices = perm[:budget]\n",
    "\n",
    "top_k, performance_regressor = task_evaluator.top_k_query(\n",
    "    k=10,\n",
    "    x_indices=x_indices,\n",
    "    model=model,\n",
    "    reverse=True,\n",
    "    by=groupby,\n",
    "    fit_function_approximator=True\n",
    ")\n",
    "print_results(top_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use \"Active\" approximation algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARMUP] Querying 200 tasks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating tasks: 100%|██████████| 200/200 [00:01<00:00, 148.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Query] Queried 300/300 tasks\n",
      "category: Q161439    predicted rank 0  actual rank: 1  \n",
      "category: Q245761    predicted rank 1  actual rank: 6  \n",
      "category: Q172833    predicted rank 2  actual rank: 8  \n",
      "category: Q682582    predicted rank 3  actual rank: 13 \n",
      "category: Q2248059   predicted rank 4  actual rank: 19 \n",
      "category: Q29024343  predicted rank 5  actual rank: 22 \n",
      "category: Q2637814   predicted rank 6  actual rank: 28 \n",
      "category: Q13681     predicted rank 7  actual rank: 37 \n",
      "category: Q1798603   predicted rank 8  actual rank: 44 \n",
      "category: Q4006      predicted rank 9  actual rank: 47 \n",
      "Mean Rank: 22.50\n",
      "Hit Rate: 0.30\n"
     ]
    }
   ],
   "source": [
    "warmup_budget=200\n",
    "top_k, performance_regressor = task_evaluator.active_top_k_query(\n",
    "    k=10,\n",
    "    warmup_budget=warmup_budget,\n",
    "    budget=budget-warmup_budget,\n",
    "    model=model,\n",
    "    reverse=True,\n",
    "    by=groupby,\n",
    ")\n",
    "print_results(top_k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
